{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mozilla_deepspeech_api_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scgupta/ml4devs-notebooks/blob/master/speech/asr/deepspeech/mozilla_deepspeech_api_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utrU3Ul7KK0G"
      },
      "source": [
        "<h1><center>How to Efficently Apply a Function to Pandas Dataframe Rows</center></h1>\n",
        "\n",
        "<p><center>\n",
        "<address>&copy; Satish Chandra Gupta<br/>\n",
        "LinkedIn: <a href=\"https://www.linkedin.com/in/scgupta/\">scgupta</a>,\n",
        "Twitter: <a href=\"https://twitter.com/scgupta\">scgupta</a>\n",
        "</address> \n",
        "</center></p>\n",
        "\n",
        "---\n",
        "\n",
        "Blog post: [How to Build Python Transcriber Using Mozilla Deepspeech](https://www.ml4devs.com/articles/how-to-build-python-transcriber-using-mozilla-deepspeech/)\n",
        "\n",
        "Update: [Mozilla DeepSpeech](https://github.com/mozilla/DeepSpeech) is no longer maintaned, and its new home is [Coqui STT](https://github.com/coqui-ai/STT), which has same [APIs in C, Java, .NET, Python, and JavaScript](https://stt.readthedocs.io/) (and also appears that the team has moved too). This notebook is tested with the [Coqui STT 1.4.0](https://github.com/coqui-ai/STT/releases/tag/v1.4.0).\n",
        "\n",
        "From Colab menu, select: **Runtime** > **Change runtime type**, and verify that it is set to Python3, and select GPU if you want to try out GPU version.\n",
        "\n",
        "You can [pip-install Coqui STT](https://pypi.org/project/stt/):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iemeuv-jKR3P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23ce4ba-e574-49eb-80c7-e152d0dbd5d1"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zABV65yhNJ0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c348257f-8703-4e4b-8b3d-31a5529355ae"
      },
      "source": [
        "!pip install stt==1.4.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stt==1.4.0 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from stt==1.4.0) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbWIPOUwNVyI"
      },
      "source": [
        "## Download Models and Audio Files\n",
        "\n",
        "Mozilla has released models for US English, we will use those in this code lab.\n",
        "\n",
        "1. **Download the models:**\n",
        "Models can be downloaded from [Coqui Model repository](https://coqui.ai/models), for example, [English STT v1.0.0 (Large Vocabulary)](https://coqui.ai/english/coqui/v1.0.0-large-vocab) that is used here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z0dSoLJPKKY"
      },
      "source": [
        "!mkdir coqui-stt-1.0.0-models"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/model.tflite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF1uB0zSNk-O",
        "outputId": "788e5be2-6301-449d-b37c-c01fee24efc8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 08:18:43--  https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/model.tflite\n",
            "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 35.155.221.103, 54.70.21.136\n",
            "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|35.155.221.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/model.tflite [following]\n",
            "--2022-11-01 08:18:43--  https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/model.tflite\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/e6d0f95f-97dc-43ac-ac08-38660209ebbc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081843Z&X-Amz-Expires=300&X-Amz-Signature=44a10d4d9bd4d00e7d28602052dc1aad181c165d1fe8661d4d2702e0140f4683&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3Dmodel.tflite&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 08:18:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/e6d0f95f-97dc-43ac-ac08-38660209ebbc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081843Z&X-Amz-Expires=300&X-Amz-Signature=44a10d4d9bd4d00e7d28602052dc1aad181c165d1fe8661d4d2702e0140f4683&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3Dmodel.tflite&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 47332120 (45M) [application/octet-stream]\n",
            "Saving to: ‘model.tflite’\n",
            "\n",
            "model.tflite        100%[===================>]  45.14M  65.4MB/s    in 0.7s    \n",
            "\n",
            "2022-11-01 08:18:44 (65.4 MB/s) - ‘model.tflite’ saved [47332120/47332120]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/large_vocabulary.scorer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwqvk3jUFblh",
        "outputId": "6c226352-e39e-4c15-f98f-eaaed969799c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 08:19:15--  https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/large_vocabulary.scorer\n",
            "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 54.70.21.136, 35.155.221.103\n",
            "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|54.70.21.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/large_vocabulary.scorer [following]\n",
            "--2022-11-01 08:19:15--  https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/large_vocabulary.scorer\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/1df256c5-336b-424b-b7b9-a33d8262eb24?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081915Z&X-Amz-Expires=300&X-Amz-Signature=e19b0ecf0873d8ce10bd72fcfe199dd877f0721e67b3b293f23ff5e4cc218adf&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3Dlarge_vocabulary.scorer&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 08:19:15--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/1df256c5-336b-424b-b7b9-a33d8262eb24?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081915Z&X-Amz-Expires=300&X-Amz-Signature=e19b0ecf0873d8ce10bd72fcfe199dd877f0721e67b3b293f23ff5e4cc218adf&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3Dlarge_vocabulary.scorer&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132644544 (126M) [application/octet-stream]\n",
            "Saving to: ‘large_vocabulary.scorer’\n",
            "\n",
            "large_vocabulary.sc 100%[===================>] 126.50M   234MB/s    in 0.5s    \n",
            "\n",
            "2022-11-01 08:19:16 (234 MB/s) - ‘large_vocabulary.scorer’ saved [132644544/132644544]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/alphabet.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55gHX_5zP9JY",
        "outputId": "3f212741-2e9a-41fc-a901-f73ba0cd6a65"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 08:19:34--  https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/alphabet.txt\n",
            "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 54.70.21.136, 35.155.221.103\n",
            "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|54.70.21.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/alphabet.txt [following]\n",
            "--2022-11-01 08:19:34--  https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/alphabet.txt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/17a8ffed-fd5a-4225-bb12-884c66c87c62?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081935Z&X-Amz-Expires=300&X-Amz-Signature=a572d804fe2912fe2a11bc7f22e1f15abe7768611697b9de80615758368004bd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3Dalphabet.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 08:19:35--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/17a8ffed-fd5a-4225-bb12-884c66c87c62?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081935Z&X-Amz-Expires=300&X-Amz-Signature=a572d804fe2912fe2a11bc7f22e1f15abe7768611697b9de80615758368004bd&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3Dalphabet.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 329 [application/octet-stream]\n",
            "Saving to: ‘alphabet.txt’\n",
            "\n",
            "alphabet.txt        100%[===================>]     329  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-01 08:19:35 (6.98 MB/s) - ‘alphabet.txt’ saved [329/329]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/MODEL_CARD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RLXmm1FQABI",
        "outputId": "27aea837-3338-4cc2-f05f-e93f8c411414"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 08:19:28--  https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/MODEL_CARD\n",
            "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 54.70.21.136, 35.155.221.103\n",
            "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|54.70.21.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/MODEL_CARD [following]\n",
            "--2022-11-01 08:19:28--  https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/MODEL_CARD\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/b03c95a9-30e2-420d-b07e-413b44525bf0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081928Z&X-Amz-Expires=300&X-Amz-Signature=445b06c031ff7bd2c9d25e6f5b4e92d1e5b9a4b67464df433e992c0da12ce55b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3DMODEL_CARD&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 08:19:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/b03c95a9-30e2-420d-b07e-413b44525bf0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081928Z&X-Amz-Expires=300&X-Amz-Signature=445b06c031ff7bd2c9d25e6f5b4e92d1e5b9a4b67464df433e992c0da12ce55b&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3DMODEL_CARD&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4244 (4.1K) [application/octet-stream]\n",
            "Saving to: ‘MODEL_CARD’\n",
            "\n",
            "MODEL_CARD          100%[===================>]   4.14K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-01 08:19:28 (38.5 MB/s) - ‘MODEL_CARD’ saved [4244/4244]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/LOG_TESTING"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOv1BfpaQB6S",
        "outputId": "5d9bbddb-2fff-4e1b-a17f-9ab1c74fa43a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 08:19:39--  https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/LOG_TESTING\n",
            "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 54.70.21.136, 35.155.221.103\n",
            "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|54.70.21.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/LOG_TESTING [following]\n",
            "--2022-11-01 08:19:39--  https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/LOG_TESTING\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/f33b2c5a-c27e-47b1-9870-4f2a190a4a83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081939Z&X-Amz-Expires=300&X-Amz-Signature=b4c75fac90ab24b8c079dc69f866135424cd219f68df85eba0debb1ac4406283&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3DLOG_TESTING&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 08:19:39--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/f33b2c5a-c27e-47b1-9870-4f2a190a4a83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081939Z&X-Amz-Expires=300&X-Amz-Signature=b4c75fac90ab24b8c079dc69f866135424cd219f68df85eba0debb1ac4406283&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3DLOG_TESTING&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25391 (25K) [application/octet-stream]\n",
            "Saving to: ‘LOG_TESTING’\n",
            "\n",
            "LOG_TESTING         100%[===================>]  24.80K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-11-01 08:19:39 (16.2 MB/s) - ‘LOG_TESTING’ saved [25391/25391]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/LICENSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPBYunv5QC_A",
        "outputId": "903fe760-6ead-418c-d7fb-338d1c3b3f9a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-01 08:19:47--  https://coqui.gateway.scarf.sh/english/coqui/v1.0.0-large-vocab/LICENSE\n",
            "Resolving coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)... 54.70.21.136, 35.155.221.103\n",
            "Connecting to coqui.gateway.scarf.sh (coqui.gateway.scarf.sh)|54.70.21.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/LICENSE [following]\n",
            "--2022-11-01 08:19:47--  https://github.com/coqui-ai/STT-models/releases/download/english/coqui/v1.0.0-large-vocab/LICENSE\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/dc69c571-83ca-48c1-9b31-408e9be73bc1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081948Z&X-Amz-Expires=300&X-Amz-Signature=fb309e2c02840f07807419fbd64ff146d8c90536b2298a8afb5cdc512914d6ed&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3DLICENSE&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-01 08:19:48--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/351871871/dc69c571-83ca-48c1-9b31-408e9be73bc1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221101%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221101T081948Z&X-Amz-Expires=300&X-Amz-Signature=fb309e2c02840f07807419fbd64ff146d8c90536b2298a8afb5cdc512914d6ed&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=351871871&response-content-disposition=attachment%3B%20filename%3DLICENSE&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11358 (11K) [application/octet-stream]\n",
            "Saving to: ‘LICENSE’\n",
            "\n",
            "LICENSE             100%[===================>]  11.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-01 08:19:48 (75.1 MB/s) - ‘LICENSE’ saved [11358/11358]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv model.tflite large_vocabulary.scorer alphabet.txt MODEL_CARD LOG_TESTING LICENSE coqui-stt-1.0.0-models/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmxn7NKYGqRR",
        "outputId": "61f16357-eff1-4214-ec7c-f20470d11ded"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat 'model.tflite': No such file or directory\n",
            "mv: cannot stat 'large_vocabulary.scorer': No such file or directory\n",
            "mv: cannot stat 'alphabet.txt': No such file or directory\n",
            "mv: cannot stat 'MODEL_CARD': No such file or directory\n",
            "mv: cannot stat 'LOG_TESTING': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l coqui-stt-1.0.0-models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flAYDslHHVZK",
        "outputId": "78b9e537-d7bb-4abc-b9de-6eb0f0e5c32b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 175812\n",
            "-rw-r--r-- 1 root root       329 Dec  7  2021 alphabet.txt\n",
            "-rw-r--r-- 1 root root 132644544 Dec  7  2021 large_vocabulary.scorer\n",
            "-rw-r--r-- 1 root root     11358 Dec  7  2021 LICENSE\n",
            "-rw-r--r-- 1 root root     25391 Dec  7  2021 LOG_TESTING\n",
            "-rw-r--r-- 1 root root      4244 Dec  7  2021 MODEL_CARD\n",
            "-rw-r--r-- 1 root root  47332120 Dec  7  2021 model.tflite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g5hZVWXO1wl"
      },
      "source": [
        "2. **Download audio data files**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -LO https://github.com/coqui-ai/STT/releases/download/v1.4.0/audio-1.4.0.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdOxbBycM-Hf",
        "outputId": "21155c02-7243-46df-df5b-d0ed1b91299d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  193k  100  193k    0     0   554k      0 --:--:-- --:--:-- --:--:--  554k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4yZaht2PH_5"
      },
      "source": [
        "4. **Unzip audio files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82DLg4JpPOVX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291e0b8f-3a98-4052-99f8-804da5ccb633"
      },
      "source": [
        "!tar -xvzf audio-1.4.0.tar.gz"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "._audio\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "audio/\n",
            "audio/._2830-3980-0043.wav\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "audio/2830-3980-0043.wav\n",
            "audio/._Attribution.txt\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "audio/Attribution.txt\n",
            "audio/._4507-16021-0012.wav\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "audio/4507-16021-0012.wav\n",
            "audio/._8455-210777-0068.wav\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "audio/8455-210777-0068.wav\n",
            "audio/._License.txt\n",
            "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.xattr.com.apple.quarantine'\n",
            "audio/License.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zExydudVPU4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e128076-06aa-4588-933e-bf086b15dbc2"
      },
      "source": [
        "!ls -l ./audio/"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 260\n",
            "-rw-r--r-- 1 501 staff 63244 Nov 18  2017 2830-3980-0043.wav\n",
            "-rw-r--r-- 1 501 staff 87564 Nov 18  2017 4507-16021-0012.wav\n",
            "-rw-r--r-- 1 501 staff 82924 Nov 18  2017 8455-210777-0068.wav\n",
            "-rw-r--r-- 1 501 staff   340 May 14  2018 Attribution.txt\n",
            "-rw-r--r-- 1 501 staff 18652 May 12  2018 License.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIiwclaXPzfm"
      },
      "source": [
        "5. **Test that it all works**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!stt --help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJlSpiHSPebH",
        "outputId": "ac081218-9876-4357-e3e1-64f2d182fc3c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: stt [-h] --model MODEL [--scorer SCORER] --audio AUDIO\n",
            "           [--beam_width BEAM_WIDTH] [--lm_alpha LM_ALPHA] [--lm_beta LM_BETA]\n",
            "           [--version] [--extended] [--json]\n",
            "           [--candidate_transcripts CANDIDATE_TRANSCRIPTS]\n",
            "           [--hot_words HOT_WORDS]\n",
            "\n",
            "Running Coqui STT inference.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         Path to the model (protocol buffer binary file)\n",
            "  --scorer SCORER       Path to the external scorer file\n",
            "  --audio AUDIO         Path to the audio file to run (WAV format)\n",
            "  --beam_width BEAM_WIDTH\n",
            "                        Beam width for the CTC decoder\n",
            "  --lm_alpha LM_ALPHA   Language model weight (lm_alpha). If not specified,\n",
            "                        use default from the scorer package.\n",
            "  --lm_beta LM_BETA     Word insertion bonus (lm_beta). If not specified, use\n",
            "                        default from the scorer package.\n",
            "  --version             Print version and exits\n",
            "  --extended            Output string from extended metadata\n",
            "  --json                Output json from metadata with timestamp of each word\n",
            "  --candidate_transcripts CANDIDATE_TRANSCRIPTS\n",
            "                        Number of candidate transcripts to include in JSON\n",
            "                        output\n",
            "  --hot_words HOT_WORDS\n",
            "                        Hot-words and their boosts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!stt --model coqui-stt-1.0.0-models/model.tflite --scorer coqui-stt-1.0.0-models/large_vocabulary.scorer --audio ./audio/2830-3980-0043.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCn27zQOOM3Y",
        "outputId": "91758f29-08cc-42ce-cefe-99835551edab"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from file coqui-stt-1.0.0-models/model.tflite\n",
            "TensorFlow: v2.9.1-11-gf8242ebc005\n",
            " Coqui STT: v1.4.0-0-gfcec06bd\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "Loaded model in 0.00152s.\n",
            "Loading scorer from files coqui-stt-1.0.0-models/large_vocabulary.scorer\n",
            "Loaded scorer in 0.00023s.\n",
            "Running inference.\n",
            "experience proves this\n",
            "Inference took 0.654s for 1.975s audio file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!stt --model coqui-stt-1.0.0-models/model.tflite --scorer coqui-stt-1.0.0-models/large_vocabulary.scorer --audio ./audio/4507-16021-0012.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-kHdWHZPHyG",
        "outputId": "178add8c-b52f-4f4c-ff84-811d983930d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from file coqui-stt-1.0.0-models/model.tflite\n",
            "TensorFlow: v2.9.1-11-gf8242ebc005\n",
            " Coqui STT: v1.4.0-0-gfcec06bd\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "Loaded model in 0.0018s.\n",
            "Loading scorer from files coqui-stt-1.0.0-models/large_vocabulary.scorer\n",
            "Loaded scorer in 0.000355s.\n",
            "Running inference.\n",
            "why should one halt on the way\n",
            "Inference took 0.876s for 2.735s audio file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!stt --model coqui-stt-1.0.0-models/model.tflite --scorer coqui-stt-1.0.0-models/large_vocabulary.scorer --audio ./audio/8455-210777-0068.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lZBwBRDPHtu",
        "outputId": "6f339827-6d79-4d9b-dc08-665810ae6d00"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from file coqui-stt-1.0.0-models/model.tflite\n",
            "TensorFlow: v2.9.1-11-gf8242ebc005\n",
            " Coqui STT: v1.4.0-0-gfcec06bd\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "Loaded model in 0.00217s.\n",
            "Loading scorer from files coqui-stt-1.0.0-models/large_vocabulary.scorer\n",
            "Loaded scorer in 0.0003s.\n",
            "Running inference.\n",
            "your power is sufficient i said\n",
            "Inference took 0.851s for 2.590s audio file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the output of the last three commands, and you will see results “experience proof this, “why should one halt on the way”, and “your power is sufficient i said” respectively. You are all set.\n",
        "\n",
        "If you want the breakup and timestamp, you can use `--json` flag:"
      ],
      "metadata": {
        "id": "_4m0A8-VTPQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!stt --json --model coqui-stt-1.0.0-models/model.tflite --scorer coqui-stt-1.0.0-models/large_vocabulary.scorer --audio ./audio/8455-210777-0068.wav "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DohT6qE5SvXF",
        "outputId": "81795f63-0de7-4450-f4d0-624b13ddb59d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from file coqui-stt-1.0.0-models/model.tflite\n",
            "TensorFlow: v2.9.1-11-gf8242ebc005\n",
            " Coqui STT: v1.4.0-0-gfcec06bd\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "Loaded model in 0.00162s.\n",
            "Loading scorer from files coqui-stt-1.0.0-models/large_vocabulary.scorer\n",
            "Loaded scorer in 0.000252s.\n",
            "Running inference.\n",
            "{\n",
            "  \"transcripts\": [\n",
            "    {\n",
            "      \"confidence\": -31.462177276611328,\n",
            "      \"words\": [\n",
            "        {\n",
            "          \"word\": \"your\",\n",
            "          \"start_time\": 0.72,\n",
            "          \"duration\": 0.2\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"power\",\n",
            "          \"start_time\": 0.98,\n",
            "          \"duration\": 0.2\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"is\",\n",
            "          \"start_time\": 1.28,\n",
            "          \"duration\": 0.1\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"sufficient\",\n",
            "          \"start_time\": 1.44,\n",
            "          \"duration\": 0.36\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"i\",\n",
            "          \"start_time\": 1.92,\n",
            "          \"duration\": 0.12\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"said\",\n",
            "          \"start_time\": 2.1,\n",
            "          \"duration\": 0.08\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"confidence\": -36.81807327270508,\n",
            "      \"words\": [\n",
            "        {\n",
            "          \"word\": \"our\",\n",
            "          \"start_time\": 0.76,\n",
            "          \"duration\": 0.16\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"power\",\n",
            "          \"start_time\": 0.98,\n",
            "          \"duration\": 0.2\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"is\",\n",
            "          \"start_time\": 1.28,\n",
            "          \"duration\": 0.1\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"sufficient\",\n",
            "          \"start_time\": 1.44,\n",
            "          \"duration\": 0.36\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"i\",\n",
            "          \"start_time\": 1.92,\n",
            "          \"duration\": 0.12\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"said\",\n",
            "          \"start_time\": 2.1,\n",
            "          \"duration\": 0.08\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"confidence\": -37.49082565307617,\n",
            "      \"words\": [\n",
            "        {\n",
            "          \"word\": \"your\",\n",
            "          \"start_time\": 0.72,\n",
            "          \"duration\": 0.2\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"power\",\n",
            "          \"start_time\": 0.98,\n",
            "          \"duration\": 0.2\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"is\",\n",
            "          \"start_time\": 1.28,\n",
            "          \"duration\": 0.1\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"sufficient\",\n",
            "          \"start_time\": 1.44,\n",
            "          \"duration\": 0.36\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"i\",\n",
            "          \"start_time\": 1.92,\n",
            "          \"duration\": 0.12\n",
            "        },\n",
            "        {\n",
            "          \"word\": \"said\",\n",
            "          \"start_time\": 2.1,\n",
            "          \"duration\": 0.1\n",
            "        }\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "Inference took 0.843s for 2.590s audio file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p61UrYSvQrOd"
      },
      "source": [
        "# DeepSpeech API\n",
        "\n",
        "1.   **Import deepspeech**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKwSvpvaRFIe"
      },
      "source": [
        "import stt"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqd6bQ_gRPOB"
      },
      "source": [
        "2. **Create a model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKDVOmbFRR1A"
      },
      "source": [
        "model_file_path = 'coqui-stt-1.0.0-models/model.tflite'\n",
        "model = stt.Model(model_file_path)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNRxsb2zRgeJ"
      },
      "source": [
        "3. **Add scorer and other parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FRX1EvDRnLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c572162-1289-4292-b08d-d8adfe669776"
      },
      "source": [
        "scorer_file_path = 'coqui-stt-1.0.0-models/large_vocabulary.scorer'\n",
        "model.enableExternalScorer(scorer_file_path)\n",
        "\n",
        "lm_alpha = 0.75\n",
        "lm_beta = 1.85\n",
        "model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
        "\n",
        "beam_width = 500\n",
        "model.setBeamWidth(beam_width)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWbHnlwCRuDo"
      },
      "source": [
        "## Batch API\n",
        "\n",
        "1.   **Read an input wav file**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRshwTMoSFEL"
      },
      "source": [
        "import wave\n",
        "filename = 'audio/8455-210777-0068.wav'\n",
        "w = wave.open(filename, 'r')\n",
        "rate = w.getframerate()\n",
        "frames = w.getnframes()\n",
        "buffer = w.readframes(frames)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAowLS39SNC_"
      },
      "source": [
        "Checkout sample rate and buffer type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHvatdmxSYGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1ed738-90f7-48c3-ee73-879ad1032ff6"
      },
      "source": [
        "print(rate)\n",
        "print(model.sampleRate())\n",
        "print(str(type(buffer)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16000\n",
            "16000\n",
            "<class 'bytes'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOhbO3iTS3ft"
      },
      "source": [
        "As you can see that the speech sample rate of the wav file is 16000hz, same as the model’s sample rate. But the buffer is a byte array, whereas DeepSpeech model expects 16-bit int array.\n",
        "\n",
        "2.  **Convert byte array buffer to int16 array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYXF6AU2S8m2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b658673f-8122-4a56-b655-a9eef149fd79"
      },
      "source": [
        "import numpy as np\n",
        "data16 = np.frombuffer(buffer, dtype=np.int16)\n",
        "print(str(type(data16)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyIxzx1zTVFp"
      },
      "source": [
        "3.  **Run speech-to-text in batch mode to get the text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdzZteC7TZDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c385dc-f503-43c9-ed83-0c80427d75fe"
      },
      "source": [
        "text = model.stt(data16)\n",
        "print(text)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your power is sufficient i said\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUCXp-5uTh0L"
      },
      "source": [
        "## Streaming API\n",
        "\n",
        "Now let’s accomplish the same using streaming API. It consists of 3 steps: open session, feed data, close session.\n",
        "\n",
        "1.  **Open a streaming session**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMSQ2VYCTyao"
      },
      "source": [
        "stt_stream = model.createStream()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK4QDAZtT3QZ"
      },
      "source": [
        "2.  **Repeatedly feed chunks of speech buffer, and get interim results if desired**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScS6c2QQT72-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6efacf2-8ae8-4f60-d80f-6fc517d5203f"
      },
      "source": [
        "buffer_len = len(buffer)\n",
        "offset = 0\n",
        "batch_size = 16384\n",
        "text = ''\n",
        "while offset < buffer_len:\n",
        "    end_offset = offset + batch_size\n",
        "    chunk = buffer[offset:end_offset]\n",
        "    data16 = np.frombuffer(chunk, dtype=np.int16)\n",
        "    stt_stream.feedAudioContent(data16)\n",
        "    text = stt_stream.intermediateDecode()\n",
        "    print(text)\n",
        "    offset = end_offset"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "your power \n",
            "your power is suff\n",
            "your power is sufficient i said\n",
            "your power is sufficient i said\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeV7x1NgUK-p"
      },
      "source": [
        "3.  **Close stream and get the final result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS0WtnF5UM4n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5eb358e-d915-454b-9aca-42054bd3ed90"
      },
      "source": [
        "text = stt_stream.finishStream()\n",
        "print(text)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your power is sufficient i said\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-vbd5CmUmsY"
      },
      "source": [
        "Verify that the output is same as as the batch API output: \"your power is sufficient i said.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNGdkq0fV-n"
      },
      "source": [
        "# Recap\n",
        "\n",
        "DeepSpeech has two modes: batch and streaming. First step is to create a model object, and then either call `stt()` or `feedAudioContnet()` to transcribe audio to text."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "<p>Copyright &copy 2020 - 2022 <a href=\"https://www.linkedin.com/in/scgupta\">Satish Chandra Gupta</a>.</p>\n",
        "<img src=\"https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png\" align=\"left\"/> <p>&nbsp;<a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">CC BY-NC-SA 4.0 International</a> License.</p>"
      ],
      "metadata": {
        "id": "YJp2Lkt8WNoN"
      }
    }
  ]
}